<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://tusharganguli.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://tusharganguli.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-04T09:24:17+00:00</updated><id>https://tusharganguli.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">What is a Random Variable? (Draft)</title><link href="https://tusharganguli.github.io/blog/2024/random-variable/" rel="alternate" type="text/html" title="What is a Random Variable? (Draft)"/><published>2024-11-17T12:22:11+00:00</published><updated>2024-11-17T12:22:11+00:00</updated><id>https://tusharganguli.github.io/blog/2024/random-variable</id><content type="html" xml:base="https://tusharganguli.github.io/blog/2024/random-variable/"><![CDATA[<h1 id="definition-of-a-random-variable">Definition of a Random Variable</h1> <p>According to Gubner [1], Note 2.1, A function X from \(\Omega\) into \(\mathbb{R}\) is a random variable if and only if,</p> \[\{\omega \in \Omega : X(\omega) \in B\} \in \mathcal{A}, \; \forall B \in \mathcal{B}\] <p>Here:</p> <ul> <li>\(\Omega\) : is the sample space.</li> <li>\(\omega\): outcome defined in the sample space.</li> <li>\(\mathcal{A}\): \(\sigma\)-algebra defined on subsets of sample space (\(\Omega\)).</li> <li>\(\mathcal{B}\): Borel \(\sigma\)-field is the smallest \(\sigma\)-algebra on \(\mathbb{R}\) containing all open subsets of \(\mathbb{R}\).</li> <li>\(B\): is the Borel set such that \(B \in \mathcal{B}\).</li> </ul> <p>where:</p> <ol> <li>\(\{\omega \in \Omega : X(\omega) \in B \}\): is the preimage of the Borel set \(B\) under the random variable \(X\). It is a subset of \(\Omega\), representing the set of outcomes \(\omega\) that map to values in \(B\) under \(X\).</li> <li>\(\in \mathcal{A}\): This subset must belong to the \(\sigma\)-algebra \(\mathcal{A}\) i.e., the preimage of any Borel set \(B\) is an event that can be measured (assigned a probability).</li> </ol> <p>If you understand the above definition in its entirety, then I congratulate you on your grasp of this fundamental concept of probability. If, on the other hand, you do not completely understand the above definition and struggle like me, then you are welcome to partake in this journey of understanding the nooks and crannies of <em>“how a random variable is defined”</em>.</p> <hr/> <h1 id="aim">Aim</h1> <p>The purpose of defining a random variable is to be able to study the probability associated with an experiment.</p> <hr/> <h1 id="sample-space-outcomes-and-events">Sample Space, Outcomes and Events</h1> <p>When we run an experiment it could produce many possible outcomes. Set of all such possible outcomes is the sample space (\(\Omega\)) of the experiment. A subset of the sample space, which is a collection of possible outcomes is called an event.</p> <h2 id="example">Example</h2> <p>Consider an experiment involving ten successive coin tosses.</p> <p><strong>Experiment</strong>: Ten successive coin tosses.</p> <p><strong>Outcomes</strong>: Each outcome is a \(10\) character string with each character is either a H or T.</p> \[\begin{align*} \omega_1 &amp;= \text{HHTTTHHTHH} \\ \omega_2 &amp;= \text{HTHHTTTHHH} \end{align*}\] <p><strong>Sample Space</strong>: Set of all such outcomes is the sample space \(\Omega\)</p> \[\Omega = \{ \text{HHHHHHHHHH}, \text{HTHHTTTHHH}, \text{TTTTTTTTTT}, \cdots \}\] <p>The total number of possible outcomes of the sample space is, \(\vert\Omega\vert = 2^{10} = 1024\).</p> <p><strong>Events</strong>: An event is a subset of the sample space. Some examples are:</p> <ul> <li> <p><strong>First Head Occurs on the 3rd Toss</strong>: The set of outcomes where the first Head appears on the 3rd toss:</p> \[E_1 = \{\omega \in \Omega : \omega = \text{TTHTTTTTTT or } \omega = \text{TTHHHHHHHH and so on.}\}\] </li> <li> <p><strong>Exactly 4 Heads in 10 Tosses</strong>: The set of outcomes with exactly 4 Heads: \(E_2 = \{\omega \in \Omega : \text{Number of H in } \omega = 4\}\)</p> </li> </ul> <p>The immediate question that arises is how all this fits into the defnition of a random variable. Now let’s formally define a random variable \(X\):</p> \[\begin{equation} X(\omega) : \Omega \rightarrow \mathbb{R} \end{equation}\] <p>Here:</p> <ul> <li>\(\Omega\) represents the sample space, which is the set of all possible outcomes of the random experiment.</li> <li>\(\mathbb{R}\) is the set of real numbers.</li> <li>\(X(\omega)\) represents the random variable that maps the outcome (\(\omega\)) to the real line (\(\mathbb{R}\)). It is also a real-valued function.</li> </ul> <p>A random variable acts as a bridge, translating outcomes (\(\omega\)) into numerical values (\(\mathbb{R}\)).</p> <ul> <li>The outcomes (\(\omega\)) that belong in the sample space (\(\Omega\)), correspond to the measure (distribution) that we want to study mathematically.</li> <li>The measure is already present in these outcomes (\(\omega\)) and we define a random variable (\(X\)) to map that measure to the Real line (\(\mathbb{R}\)).</li> </ul> <p><strong>Q. What is the purpose of this mapping?</strong></p> <p>The purpose of this mapping is to study the statistical properties of the random variable \(X\), which encapsulates the behavior of outcomes in the sample space. In statistical terms, the properties of a random variable are often described using measures like mean, variance, and higher-order moments. These measures summarize key aspects of the data, such as its central tendency (mean) and variability (variance). The moments of a random variable \(X\) like mean (\(\mathbb{E}[X]\)) and variance (\(\text{Var}(X)\)) provide critical insights into the distribution of \(X\). Higher-order moments (e.g., skewness and kurtosis) offer a more nuanced understanding of the behavior of \(X\). This mathematical representation allows us to gain significant insights into the behavior of a random variable through its moments.The exercise of creating a random variable is about defining a mapping from a sample space (\(\Omega\)) to the real numbers (\(\mathbb{R}\)).</p> <p>For example, if we define the random variable \(X\) as the number of heads in 2 successive coin flips, then \(X\)(No of Heads) \(= \{0,1,2\}\). The mapping defined by the random variable \(X\) induces a distribution from the underlying probability measure \(P\) on the sample space \(\Omega\). In this example we can say that \(X\) follows a Binomial distribution. This is because the random variable \(X\) transforms the distribution on the sample space \(\Omega\) into a distribution on the real line.</p> <hr/> <h1 id="types-of-random-variable">Types of Random Variable</h1> <p>Depending on the range of numerical values that the random variable \(X\) can take, a random variable is either a discrete random variable or a continuous random variable.</p> <ul> <li><strong>Discrete Random Variable</strong>: If the range of the random variable is finite or countably infinite.</li> <li><strong>Continuous Random Variable</strong>: If the range of the random variable is uncountably infinite.</li> </ul> <hr/> <h1 id="cardinality-of-a-set">Cardinality of a Set</h1> <p>The cardinality of a set refers to the size or number of elements in the set. Sets can have different cardinalities, which are broadly categorized as finite, countably infinite, and uncountably infinite.</p> <ul> <li> <p>A <strong>countably finite set</strong> is a set with a finite number of elements and can be put into a one-to-one correspondence with the first \(n\) positive integers, where \(n\) is finite.</p> <ul> <li><strong>Example</strong>: The set \(A = \{2, 4, 6, 8\}\) has 4 elements that correspond to the natural numbers \(\{1, 2, 3, 4\}\).</li> </ul> </li> <li> <p>A <strong>countably infinite set</strong> is a set with infinitely many elements, but these elements can still be put into a one-to-one correspondence with the set of natural numbers (\(\mathbb{N}\)).</p> <ul> <li><strong>Examples</strong>: <ul> <li>The set of all natural numbers: \(\mathbb{N} = \{1, 2, 3, 4, \dots\}\).</li> <li>The set of all integers: \(\mathbb{Z} = \{\dots, -2, -1, 0, 1, 2, \dots\}\). - \(\mathbb{Z}\) can be mapped to \(\mathbb{N}\) using: \(f(n) = \begin{cases} 2n &amp; \text{if } n &gt; 0 \\ -2n + 1 &amp; \text{if } n \leq 0 \end{cases}\)</li> <li>The set of even numbers, \(E = \{2, 4, 6, 8, \dots\}\) maps \(E \to \mathbb{N}\) with \(f(n) = 2n\).</li> </ul> </li> </ul> </li> <li> <p>A set is <strong>uncountably infinite</strong> if it contains infinitely many elements that cannot be put into a one-to-one correspondence with the set of natural numbers (\(\mathbb{N}\)). In other words, the set is too large to be enumerated, even in principle.</p> <ul> <li><strong>Example</strong>: The interval \([0, 1] \subset \mathbb{R}\) is uncountably infinite. This can be proven by Cantor’s diagonal argument, which demonstrates that no list can include all real numbers.</li> </ul> </li> </ul> <hr/> <h1 id="example-of-different-types-of-random-variable">Example of Different Types of Random Variable</h1> <ul> <li><strong>Discrete Random Variable - Countably Finite</strong>: <ul> <li>Experiment: Two successive rolls of a die.</li> <li>Random Variable: The sum of the two rolls is less than \(8\).</li> </ul> </li> <li><strong>Discrete Random Variable - Countably Infinite</strong>: <ul> <li>Experiment: Roll a single six-sided die repeatedly where the sample space for each roll is \(\Omega={1,2,3,4,5,6}\).</li> <li>Random Variable: The roll count on which \(6\) appears for the first time.</li> </ul> </li> <li><strong>Continuous Random Variable - Uncountably Infinite</strong>: <ul> <li>Experiment: Choosing a point \(a\) from the interval \([0,1]\).</li> <li>Random Variable: Associate the value \(a^2\) to such a point.</li> </ul> </li> </ul> <hr/> <h1 id="probability">Probability</h1> <ul> <li>The probability law assigns probabilities to event (\(A\)), which is a subset of the sample space (\(A \subseteq \Omega\)).</li> <li><strong>Remember</strong>: Random variable assigns values to outcomes.</li> </ul> <h2 id="example-1">Example</h2> <ul> <li>Experiment: Toss a coin three times.</li> <li>Sample Space: \(\Omega = \{\text{HHH},\text{HHT},\text{HTH},\text{HTT},\text{THH},\text{THT},\text{TTH},\text{TTT}\}\)</li> <li> <p>Random Variable: Let \(X\) represent the number of heads:</p> \[\begin{align*} X(\text{HHH}) &amp;= 3 \\ X(\text{HHT}) &amp;= X(\text{HTH}) = X(\text{THH}) = 2 \\ X(\text{HTT}) &amp;= X(\text{THT}) = X(\text{TTH}) = 1 \\ X(\text{TTT}) &amp;= 0 \end{align*}\] </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/rv-480.webp 480w,/assets/img/rv-800.webp 800w,/assets/img/rv-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/rv.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> X = {Number of Heads}. </div> <ul> <li>Let the event be, “The number of heads is 2”, which would be represented by: \(\{\text{HHT}, \text{HTH}, \text{THH}\} \subseteq \Omega\)</li> <li>The probability of an event would be calculated by summing the probabilities of the outcomes in that event. <ul> <li>As \(\{X=2\} = \{\text{HHT}, \text{HTH}, \text{THH}\}\), hence: \(P\{(X = 2)\} = P(\text{HHT}) + P(\text{HTH}) + P(\text{THH}) = \frac{1}{8} + \frac{1}{8} + \frac{1}{8} = \frac{3}{8}.\)</li> </ul> </li> </ul> <p>Hence, the random variable \(X\) creates a mapping from \(\Omega\) to \(\mathbb{R}\) and the probability law assigns probabilities to events such as \(\{X = x\}\), allowing us to compute the probability distribution of \(X\).</p> <hr/> <h1 id="probability-mass-function">Probability Mass Function</h1> <p>Now that we understand how random variables are defined and how probabilities are assigned, let’s tie all this up together.</p> <p>A random variable \(X\) is a function that maps each outcome \(\omega \in \Omega\) to a value \(x \in \mathbb{R}\). Different outcomes in the sample space \(\Omega\) can map to the same value \(x\) under \(X\).</p> <p>The probability mass function \(p_X(x)\) is defined as the probability of the event \(\{X = x\}\), which includes all outcomes in \(\Omega\) that result in \(X(\omega) = x\).</p> \[p_X(x) = P(\{X=x\})\] <p>Here, \(x\) is any possible value of \(X\), the probability mass of \(x\), denoted \(p_X(x)\), is the probability of the event \(\{X = x\}\) consisting of all outcomes that give rise to a value of \(X\) equal to \(x\). The previous example defines the random variable and demonstrates an example of how a specific event (\(P\{X=2\}\)) is assigned probability value.</p> <p><strong>Q. What does it mean when we say: The random variable \(X\) has a binomial distribution?</strong></p> <p>If \(X\) is a binomial random variable with parameters \(n\) and \(p\). Then the PMF of \(X\) is defined as:</p> \[P(\{X=k\}) = \binom{n}{x}p^x(1-p)^{n-x}\] <p>The above equation:</p> <ul> <li>Describes the probabilities of all possible values the random variable \(X\) can take.</li> <li>The event \(\{X=k\}\) is a subset of the sample space \(\Omega\) and contains all outcomes (\(\omega\)) for which \(X(\omega) = k\).</li> </ul> <hr/> <h1 id="continuous-random-variable">Continuous Random Variable</h1> <p>A continuous random variable can take an infinite number of possible values within a given range on the real line (\(\mathbb{R}\)). Continuous random variables can take on any value within an interval or collection of intervals on the real number line. For example, a random variable representing the height of people could be any real number within a plausible range (e.g., between 150 cm and 200 cm).</p> <p>Similar to a discrete random variable which is characterized by its PMF, a continuous random variable is described by a probability density function (PDF), denoted by \(f_{X}(x)\). The PDF gives the relative likelihood that the variable takes a particular value.</p> <p>Unlike a probability mass function (PMF) for discrete random variables, the PDF is not the probability of a specific value. The probability that the random variable takes on a specific value is always zero for a continuous variable. Rather, the PDF is used to compute the probability that the random variable lies within a certain interval.</p> \[\mathcal{P}(a \leq X \leq b) = \int_{a}^{b} f_{X}(x) dx\] <p>and can be interpreted as the area under the graph of the PDF.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pdf-480.webp 480w,/assets/img/pdf-800.webp 800w,/assets/img/pdf-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/pdf.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Reference [2], Figure 3.1. PDF Illustration. </div> <hr/> <h1 id="continuous-models">Continuous Models</h1> <h1 id="references">References</h1> <p><strong>“If I have seen further, it is by standing on the shoulders of giants.”</strong><br/> <em>— Sir Isaac Newton</em></p> <ol> <li>Gubner, John A. <em>Probability and Random Processes for Electrical and Computer Engineers</em>. Cambridge University Press, 2006.</li> <li><a href="https://vfu.bg/en/e-Learning/Math--Bertsekas_Tsitsiklis_Introduction_to_probability.pdf">Introduction to Probability, by Dimitri P. Bertsekas and John N. Tsitsiklis</a></li> </ol>]]></content><author><name></name></author><category term="Probability"/><category term="randomvariable"/><category term="probability"/><summary type="html"><![CDATA[exposition on the definition of random variable.]]></summary></entry><entry><title type="html">End-To-End RAG Building</title><link href="https://tusharganguli.github.io/blog/2024/end-to-end-rag-building/" rel="alternate" type="text/html" title="End-To-End RAG Building"/><published>2024-10-29T21:15:01+00:00</published><updated>2024-10-29T21:15:01+00:00</updated><id>https://tusharganguli.github.io/blog/2024/end-to-end-rag-building</id><content type="html" xml:base="https://tusharganguli.github.io/blog/2024/end-to-end-rag-building/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Evaluation Framework using LLM-As-A-Judge</title><link href="https://tusharganguli.github.io/blog/2024/evaluation_framework/" rel="alternate" type="text/html" title="Evaluation Framework using LLM-As-A-Judge"/><published>2024-08-12T12:22:11+00:00</published><updated>2024-08-12T12:22:11+00:00</updated><id>https://tusharganguli.github.io/blog/2024/evaluation_framework</id><content type="html" xml:base="https://tusharganguli.github.io/blog/2024/evaluation_framework/"><![CDATA[<p><strong>Disclaimer</strong> This work was completed by me on behalf of Dataworkz. <br/>Original Article: <a href="https://www.dataworkz.com/2024/08/12/dataworkz-rag-builder-evaluation-framework/">Dataworkz RAG Builder: Evaluation Framework</a></p> <h1 id="evaluation-framework">Evaluation Framework</h1> <p>The most popular metrics for evaluating QnA systems are BLEU, ROUGE-N, and BertScore. These metrics measure textual similarity but can sometimes be misleading. For example, two LLM responses might be phrased differently yet satisfy the same customer need, or two similarly phrased responses may vary significantly in their effectiveness. To address this, it is essential to have an evaluation model that reflects the intended customer experience. Such a model should capture the subjective experience of each individual answer. This requires human evaluators—typically domain experts—who can provide nuanced assessments. To combine both automated and subjective evaluation, we introduce an evaluation method leverages LLM-as-a-Judge that captures the essence of a response and provides a measurable metrics. We tested against publicly available datasets and QA benchmarks, highlighting limitations of existing metrics and introducing a more effective solution.</p> <hr/> <h2 id="evaluation-metrics">Evaluation Metrics</h2> <p>We incorporate the following three evaluation metrics:</p> <ol> <li>Answer Accuracy – Comparison of the golden answer to the generated answer.</li> <li>Context Relevance – Comparison of the golden context to the generated context.</li> <li>Faithfulness – Comparison of the golden context to the generated answer.</li> </ol> <p>This blog focuses on Answer Accuracy, with subsequent blogs covering the remaining metrics.</p> <hr/> <h2 id="i-answer-accuracy">I. Answer Accuracy</h2> <h3 id="setup">Setup</h3> <p>We used a publicly available finance dataset, Apple 10-K filing for fiscal year 2022, and FinQABench, a QA benchmark designed for financial applications based on Apple’s 2022 10-K filing.</p> <ul> <li>FinQABench: Contains 100 questions with golden answers and contexts.</li> <li>Evaluated Metrics: BLEU Score, ROUGE-1, ROUGE-L, BertScore (Precision, Recall, F1), and Similarity Score.</li> </ul> <h3 id="results-and-observations-with-existing-metrics">Results and Observations with Existing Metrics</h3> <p>Results for 100 FinQABench questions revealed the following average scores:</p> <table> <thead> <tr> <th>BLEU Score</th> <th>ROUGE-1</th> <th>ROUGE-L</th> <th>BERT Precision</th> <th>BERT Recall</th> <th>BERT F1</th> <th>Similarity</th> </tr> </thead> <tbody> <tr> <td>0.2951</td> <td>0.5533</td> <td>0.5095</td> <td>0.3158</td> <td>0.5354</td> <td>0.4191</td> <td>0.7302</td> </tr> </tbody> </table> <h4 id="key-observations">Key Observations</h4> <ul> <li>Existing metrics often fail to evaluate numerical or differently formatted data accurately.</li> <li>Semantic similarity is inconsistent across various question types.</li> <li>Misalignment between golden answers and generated answers leads to misleading metrics.</li> </ul> <h5 id="examples-fact-based-qna">Examples: Fact-Based QnA</h5> <p>In the table below, although all responses are correct, the scores received are substantially lower. This indicates that current metrics fail to verify the generated responses against the golden responses. A critical limitation of these metrics is exposed: if the data is numerical or not formatted exactly like the golden answer, the scores suffer significantly.</p> <table> <thead> <tr> <th>Question</th> <th>Golden Response</th> <th>Response</th> <th>BLEU Score</th> <th>ROUGE-1</th> <th>ROUGE-L</th> <th>BERT F1</th> <th>Similarity Score</th> </tr> </thead> <tbody> <tr> <td>What is the date of the certification of the Chief Executive Officer?</td> <td>2022-10-27 00:00:00</td> <td>The date of the certification is October 27, 2022.</td> <td>0.0000</td> <td>0.1481</td> <td>0.0741</td> <td>-0.6088</td> <td>0.3347</td> </tr> <tr> <td>What is the jurisdiction of incorporation of Apple South Asia (Thailand) Limited?</td> <td>Thailand</td> <td>The jurisdiction is Thailand.</td> <td>0.0000</td> <td>0.1538</td> <td>0.1538</td> <td>-0.1914</td> <td>0.5613</td> </tr> </tbody> </table> <h5 id="examples-descriptive-qna">Examples: Descriptive QnA</h5> <p>Additionally, we observe similar issues with “Descriptive QnA”. The similarity score is high in the first question, however, this score is not consistent across all types of questions. The answer to the next question in the table below is evidence to that observation. It captures the main facts of the golden answer but the similarity score is not a good measure of its relevance.</p> <table> <thead> <tr> <th>Question</th> <th>Golden Response</th> <th>Dataworkz Response</th> <th>BLEU Score</th> <th>ROUGE-1</th> <th>ROUGE-L</th> <th>BERT F1</th> <th>Similarity Score</th> </tr> </thead> <tbody> <tr> <td>What is Rule 10b5-1 Trading Plans?</td> <td>Written document that preestablishes the amounts, prices, and dates of stock purchases or sales.</td> <td>A written document preestablishing amounts, prices, and dates of stock transactions.</td> <td>0.5538</td> <td>0.9216</td> <td>0.9216</td> <td>0.7631</td> <td>0.9534</td> </tr> <tr> <td>Who signed the Annual Report on Form 10-K?</td> <td>List of Apple executives and directors.</td> <td>Detailed list of signatories, including titles.</td> <td>0.0092</td> <td>0.4516</td> <td>0.4355</td> <td>0.0993</td> <td>0.5076</td> </tr> </tbody> </table> <p>Our observations indicate that any one metric is not able to consistently reflect the quality of answer score if their explanations do not closely align with the language of the golden response. This misalignment can be misleading, it fails to accurately reflect the true quality and comprehensiveness of the Q&amp;A system’s responses when compared to the benchmark. Traditional metrics seem to have substantial constraints to correlate with human preferences. Hence, we utilized the current state-of-the-art solution to build a scalable solution which aligns well with human evaluation called “LLM-as-a-Judge”. LLM-as-a-judge is a reference-free metric that directly prompts a powerful LLM to evaluate the quality of another model’s output.</p> <hr/> <h2 id="llm-as-a-judge">LLM-as-a-Judge</h2> <h3 id="introduction">Introduction</h3> <p>LLM-as-a-Judge leverages advanced language models for reference-free evaluations, aligning responses with human preferences. Through prompt engineering, the model evaluates responses across <strong>precision</strong>, <strong>recall</strong>, and <strong>F1 score</strong>, providing more nuanced insights.</p> <h3 id="methodology">Methodology</h3> <p>We developed a generic prompt capable of evaluating all types of responses, whether they are descriptive, numerical, or factual. Our evaluation criteria, embedded within the prompt, include the following essential instructions:</p> <ol> <li>Calculate the total number of claims in the golden response with respect to the question.</li> <li>Calculate the total number of claims in the candidate response with respect to the question.</li> <li>Calculate the total number of claims common to both the golden response and the candidate response.</li> </ol> <p>This process generates lists of claims for both the golden response and the Dataworkz response. Once these claims are derived from the original responses, we calculate precision, recall, and F1 scores based on the following criteria:</p> <ul> <li>Precision: Number of claims common to both the golden response and Dataworkz response / Total number of claims in the Dataworkz response.</li> <li>Recall: Number of claims common to both the golden response and Dataworkz response / Total number of claims in the golden response.</li> <li>F1 Score: Harmonic mean of precision and recall.</li> </ul> <hr/> <h3 id="results-with-llm-as-a-judge">Results with LLM-as-a-Judge</h3> <p>LLM-AS-A-Judge was able to capture the essence of the generated responses in comparison to the golden answers. The overall result for the metrics was:</p> <table> <thead> <tr> <th>LLM Precision</th> <th>LLM Recall</th> <th>LLM F1</th> </tr> </thead> <tbody> <tr> <td>0.8252</td> <td>0.7350</td> <td>0.7490</td> </tr> </tbody> </table> <h4 id="example-fact-based-qna">Example: Fact-Based QnA</h4> <p>The table below indicates that the evaluation framework was able to correctly evaluate the fact based answers irrespective of the format of the generated answer.</p> <table> <thead> <tr> <th>Question</th> <th>Golden Response</th> <th>Generated Response</th> <th>LLM F1</th> <th>BLEU Score</th> <th>ROUGE-1</th> <th>ROUGE-L</th> <th>BERT F1</th> <th>Similarity Score</th> </tr> </thead> <tbody> <tr> <td>What is the date of the certification?</td> <td>2022-10-27 00:00:00</td> <td>October 27, 2022</td> <td>1.0000</td> <td>0.0000</td> <td>0.1481</td> <td>0.0741</td> <td>-0.6088</td> <td>0.3347</td> </tr> </tbody> </table> <h3 id="descriptive-qna">Descriptive QnA</h3> <p>The evaluation framework was also consistent across “Descriptive QnA” and was able to evaluate the content accurately.</p> <table> <thead> <tr> <th>Question</th> <th>Golden Response</th> <th>Generated Response</th> <th>LLM Score (F1)</th> <th>Bleu Score</th> <th>Rouge-1</th> <th>Rouge-L</th> <th>Bert Score (F1)</th> <th>Similarity Score</th> </tr> </thead> <tbody> <tr> <td>What is Rule 10b5-1 Trading Plans?</td> <td>Rule 10b5-1 Trading Plans is a written document that preestablishes the amounts, prices and dates (or formula for determining the amounts, prices and dates) of future purchases or sales of the Company’s stock, including sales of shares acquired under the Company’s employee and director equity plans.</td> <td>According to the context, Rule 10b5-1 Trading Plans refer to written documents that preestablish the amounts, prices, and dates (or formula for determining the amounts, prices, and dates) of future purchases or sales of the Company’s stock, including sales of shares acquired under the Company’s employee and director equity plans.</td> <td>1.0000</td> <td>0.5538</td> <td>0.9216</td> <td>0.9216</td> <td>0.7631</td> <td>0.9534</td> </tr> <tr> <td>Who signed the Annual Report on Form 10-K on behalf of the Registrant on October 27, 2022?</td> <td>Timothy D. Cook, Luca Maestri, Chris Kondo, James A. Bell, Al Gore, Alex Gorsky, Andrea Jung, Arthur D. Levinson, Monica Lozano, Ronald D. Sugar, and Susan L. Wagner.</td> <td>The following persons signed the Annual Report on Form 10-K on behalf of the Registrant on October 27, 2022: 1. Timothy D. Cook – Chief Executive Officer and Director (Principal Executive Officer) 2. Luca Maestri – Senior Vice President, Chief Financial Officer (Principal Financial Officer) 3. Chris Kondo – Senior Director of Corporate Accounting (Principal Accounting Officer) 4. James A. Bell – Director 5. Al Gore – Director 6. Alex Gorsky – Director 7. Andrea Jung – Director 8. Arthur D. Levinson – Director and Chair of the Board 9. Monica Lozano – Director 10. Ronald D. Sugar – Director 11. Susan L. Wagner – Director</td> <td>1.0000</td> <td>0.0092</td> <td>0.4516</td> <td>0.4355</td> <td>0.0993</td> <td>0.5076</td> </tr> </tbody> </table> <hr/> <h1 id="example">Example</h1> <p>To elaborate on how our evaluation system works, let us take the first question from the previous table:</p> <p>Question: What is Rule 10b5-1 Trading Plans?</p> <h2 id="part-i">Part I</h2> <p>The first part is retrieving all individual claims from each response:</p> <p>Total Number of claims in Golden response: 6</p> <ol> <li> <p>: ‘Rule 10b5-1 Trading Plans is a written document.’,</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans preestablish the amounts of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans preestablish the prices of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans preestablish the dates of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans include a formula for determining the amounts, prices, and dates of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans include sales of shares acquired under the Company’s employee and director equity plans.”</p> </li> </ol> <p>Total Number of claims in generated response: 6</p> <ol> <li> <p>: ‘Rule 10b5-1 Trading Plans refer to written documents.’</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans preestablish the amounts of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans preestablish the prices of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans preestablish the dates of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans include a formula for determining the amounts, prices, and dates of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans include sales of shares acquired under the Company’s employee and director equity plans.”</p> </li> </ol> <p>Total Number of common claims: 6</p> <ol> <li> <p>: ‘Rule 10b5-1 Trading Plans is a written document.’</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans preestablish the amounts of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans preestablish the prices of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans preestablish the dates of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans include a formula for determining the amounts, prices, and dates of future purchases or sales of the Company’s stock.”</p> </li> <li> <p>: “Rule 10b5-1 Trading Plans include sales of shares acquired under the Company’s employee and director equity plans.”</p> </li> </ol> <h2 id="part-ii">Part II</h2> <p>Calculate the metrics based on the total claims retrieved in the previous step.</p> <ul> <li>Precision: Number of common claims / Number of claims in Dataworkz response i.e. 6/6 = 1.</li> <li>Recall: Number of common claims / Number of claims in Golden response i.e. 6/6 = 1.</li> <li>F1 Score: Harmonic mean of precision and recall i.e. 1.</li> </ul> <hr/> <h1 id="final-thoughts">Final Thoughts</h1> <p>The results demonstrate that the evaluation framework comprehensively measures any QA system against existing benchmarks. By leveraging LLM-as-a-Judge, this framework surpasses standard evaluation metrics like BLEU, ROUGE, and BERTScore, offering a more nuanced and accurate assessment of QA system performance. It is evident that traditional metrics like BLEU, ROUGE and BertScore have certain limitations for evaluating QnA systems and LLM-as-a-Judge can be utilized for generating qualitative and contextual metrics.</p> <hr/> <h1 id="references">References</h1> <ul> <li><a href="https://huggingface.co/datasets/lighthouzai/finqabench">FinQABench</a></li> <li><a href="https://investor.apple.com/sec-filings/default.aspx">Apple 10-K Filing 2022</a></li> <li>BLEU Score <ul> <li><a href="https://en.wikipedia.org/wiki/BLEU">Wikipedia</a></li> <li><a href="https://medium.com/nlplanet/two-minutes-nlp-learn-the-bleu-metric-by-examples-df015ca73a86">Bleu Metrics</a></li> </ul> </li> <li>ROUGE Score <ul> <li><a href="https://en.wikipedia.org/wiki/ROUGE_(metric)">Wikipedia</a></li> <li><a href="https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499">ROUGE Metrics</a></li> </ul> </li> <li>BERT Score <ul> <li><a href="https://arxiv.org/abs/1904.09675">Paper</a></li> <li><a href="https://medium.com/@abonia/bertscore-explained-in-5-minutes-0b98553bfb71">Bert Score</a></li> </ul> </li> <li><a href="https://open.substack.com/pub/cameronrwolfe/p/llm-as-a-judge?r=35moeb&amp;utm_campaign=post&amp;utm_medium=web">Using LLMs for Evaluation</a></li> <li><a href="https://arxiv.org/abs/2306.05685">Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</a></li> </ul>]]></content><author><name></name></author><category term="LLM"/><category term="evaluation_famrwork"/><category term="llm_as_a_judge"/><summary type="html"><![CDATA[Creating an evaluation framework using llm-as-a-judge]]></summary></entry><entry><title type="html">Part 2 — Retrieval Augmented Generation using LlamaIndex</title><link href="https://tusharganguli.github.io/blog/2024/part-2retrieval-augmented-generation-using-llamaindex/" rel="alternate" type="text/html" title="Part 2 — Retrieval Augmented Generation using LlamaIndex"/><published>2024-02-22T20:44:12+00:00</published><updated>2024-02-22T20:44:12+00:00</updated><id>https://tusharganguli.github.io/blog/2024/part-2retrieval-augmented-generation-using-llamaindex</id><content type="html" xml:base="https://tusharganguli.github.io/blog/2024/part-2retrieval-augmented-generation-using-llamaindex/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Part 1 — Retrieval Augmented Generation</title><link href="https://tusharganguli.github.io/blog/2024/part-1retrieval-augmented-generation/" rel="alternate" type="text/html" title="Part 1 — Retrieval Augmented Generation"/><published>2024-02-18T22:10:34+00:00</published><updated>2024-02-18T22:10:34+00:00</updated><id>https://tusharganguli.github.io/blog/2024/part-1retrieval-augmented-generation</id><content type="html" xml:base="https://tusharganguli.github.io/blog/2024/part-1retrieval-augmented-generation/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Anomaly Detection - Classifier</title><link href="https://tusharganguli.github.io/blog/2023/anomaly_detection_classifier/" rel="alternate" type="text/html" title="Anomaly Detection - Classifier"/><published>2023-07-16T22:22:11+00:00</published><updated>2023-07-16T22:22:11+00:00</updated><id>https://tusharganguli.github.io/blog/2023/anomaly_detection_classifier</id><content type="html" xml:base="https://tusharganguli.github.io/blog/2023/anomaly_detection_classifier/"><![CDATA[<p>For categorical data an ensemble of multiple classifiers were used:</p> <ul> <li>Logistic Regression, K-Nearest Neighbor, Support Vector Classifier, Decision Tree Classifier</li> <li>Different voting classifiers were analyzed (hard and soft voting classifier).</li> <li>Calibration techniques were applied namely: Platt Scaling and Isotonic Regression.</li> </ul> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/ad_multiclassifier.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="DataScience"/><category term="anomaly_detection"/><category term="data_analysis"/><category term="time_series"/><summary type="html"><![CDATA[Techniques for Anomaly Detection using Multi-Classifier]]></summary></entry><entry><title type="html">Anomaly Detection - Time Series</title><link href="https://tusharganguli.github.io/blog/2023/anomaly_detection_timeseries/" rel="alternate" type="text/html" title="Anomaly Detection - Time Series"/><published>2023-07-16T22:22:11+00:00</published><updated>2023-07-16T22:22:11+00:00</updated><id>https://tusharganguli.github.io/blog/2023/anomaly_detection_timeseries</id><content type="html" xml:base="https://tusharganguli.github.io/blog/2023/anomaly_detection_timeseries/"><![CDATA[<p>For time series data, methods studied and implemented were:</p> <ul> <li>Isolation forest</li> <li>Local Outlier Factor</li> <li>Autoencoders</li> <li>AutoRegressive Integrated Moving Average(ARIMA)</li> <li>Moving Average</li> <li>Z-score analysis.</li> </ul> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/ad_timeseries.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="DataScience"/><category term="anomaly_detection"/><category term="data_analysis"/><category term="time_series"/><summary type="html"><![CDATA[Techniques for Anomaly Detection using Time Series]]></summary></entry></feed>